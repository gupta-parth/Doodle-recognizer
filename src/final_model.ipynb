{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final doodle recognition model \n",
    "\n",
    "Model will be trained on 100 classes from Google's QuickDraw dataset. The classes from chosen as a random sample from the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drums', 'sun', 'laptop', 'dog', 'baseball_bat', 'ladder', 'eyeglasses', 'grapes', 'book', 'dumbbell', 'traffic_light', 'wristwatch', 'wheel', 'shovel', 'bread', 'table', 'tennis_racquet', 'cloud', 'chair', 'headphones', 'face', 'eye', 'airplane', 'snake', 'lollipop', 'guitar', 'pants', 'mushroom', 'star', 'sword', 'clock', 'hot_dog', 'syringe', 'stop_sign', 'mountain', 'smiley_face', 'apple', 'bed', 'shorts', 'broom', 'diving_board', 'flower', 'spider', 'cell_phone', 'car', 'camera', 'tree', 'square', 'moon', 'radio', 'hat', 'pizza', 'axe', 'door', 'tent', 'umbrella', 'line', 'cup', 'fan', 'triangle', 'basketball', 'pillow', 'scissors', 't-shirt', 'tooth', 'alarm_clock', 'paper_clip', 'spoon', 'microphone', 'candle', 'pencil', 'envelope', 'saw', 'frying_pan', 'screwdriver', 'helmet', 'bridge', 'light_bulb', 'ceiling_fan', 'key', 'donut', 'bird', 'circle', 'beard', 'coffee_cup', 'butterfly', 'bench', 'rifle', 'cat', 'sock', 'ice_cream', 'moustache', 'suitcase', 'hammer', 'rainbow', 'knife', 'cookie', 'baseball', 'lightning', 'bicycle']\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../classes.txt\")\n",
    "categories = f.readlines()\n",
    "f.close()\n",
    "categories = [category.replace('\\n', '').replace(' ', '') for category in categories]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/guitar.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "!mkdir data\n",
    "def download_data():\n",
    "    url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "    for category in categories:\n",
    "        label_name = category.replace('_', '%20')\n",
    "        path = url + label_name + '.npy'\n",
    "        print(path)\n",
    "        urllib.request.urlretrieve(path, 'data/'+category+'.npy')\n",
    "\n",
    "download_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Using 4000 images per class as training takes a long time on this local computer (around 7 mins per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, split_ratio=0.2, class_size=4000):\n",
    "    data_folder = glob.glob(os.path.join(path, '*.npy'))\n",
    "    x = np.empty([0, 784])   # Because each image is 28 * 28\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "    for i, file_name in enumerate(data_folder):\n",
    "        data = np.load(file_name)\n",
    "        data = data[0:class_size, :]\n",
    "        labels = np.full(data.shape[0], i)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file_name))\n",
    "        class_names.append(class_name)\n",
    "    data = None\n",
    "    labels = None\n",
    "\n",
    "    # Data randomization\n",
    "    perm = np.random.permutation(y.shape[0])\n",
    "    x = x[perm, :]\n",
    "    y = y[perm]\n",
    "\n",
    "    # Split set\n",
    "    split_size = int(x.shape[0]/100*(split_ratio*100))\n",
    "\n",
    "    x_test = x[0:split_size, :]\n",
    "    y_test = y[0:split_size]\n",
    "\n",
    "    x_train = x[split_size:x.shape[0], :]\n",
    "    y_train = y[split_size:y.shape[0]]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.imshow(x_train[4000].reshape(28, 28))\n",
    "print(class_names[int(y_train[4000].item())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1).astype('float32')\n",
    "\n",
    "# Normalize\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# One hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, len(class_names))\n",
    "y_test = keras.utils.to_categorical(y_test, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Convolution2D(16, (3, 3),\n",
    "                            padding='same',\n",
    "                            input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='softmax')) \n",
    "    # Train model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['top_k_categorical_accuracy'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 110,052\n",
      "Trainable params: 110,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288000 samples, validate on 32000 samples\n",
      "Epoch 1/5\n",
      "288000/288000 - 460s - loss: 1.9857 - top_k_categorical_accuracy: 0.7706 - val_loss: 1.4209 - val_top_k_categorical_accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "288000/288000 - 463s - loss: 1.2808 - top_k_categorical_accuracy: 0.8877 - val_loss: 1.2005 - val_top_k_categorical_accuracy: 0.8957\n",
      "Epoch 3/5\n",
      "288000/288000 - 470s - loss: 1.1093 - top_k_categorical_accuracy: 0.9071 - val_loss: 1.0828 - val_top_k_categorical_accuracy: 0.9106\n",
      "Epoch 4/5\n",
      "288000/288000 - 465s - loss: 1.0161 - top_k_categorical_accuracy: 0.9173 - val_loss: 1.0214 - val_top_k_categorical_accuracy: 0.9172\n",
      "Epoch 5/5\n",
      "288000/288000 - 468s - loss: 0.9536 - top_k_categorical_accuracy: 0.9235 - val_loss: 0.9884 - val_top_k_categorical_accuracy: 0.9197\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.1, batch_size=256, verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:91.86750054359436\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Accuracy:{score[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lollipop', 'spoon', 'microphone', 'stop_sign', 'key']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze())\n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handle:\n",
    "    for i in class_names:\n",
    "        file_handle.write(f\"{i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflowjs in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (3.15.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflowjs) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.15.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.2)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.24.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.13.3)\n",
      "Requirement already satisfied: setuptools in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (58.0.4)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.6.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.21.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (13.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.6.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.11.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/parth/opt/anaconda3/envs/ml/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: model: File exists\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "!mkdir model\n",
    "!tensorflowjs_converter --input_format keras model.h5 model/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a48f42d6b2cc564c84f407a5f0014b33de5d29db06b959bd1beac822a38c3b71"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
